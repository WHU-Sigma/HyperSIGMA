<!DOCTYPE html>
<html>
<head>
  <style>
    .carousel .item {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      padding: 1rem;
      width: 100%;
      max-width: 2000px; /* ÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥ÊúÄÂ§ßÂÆΩÂ∫¶ */
    }
  
    .carousel img {
      width: 100%;
      height: auto;
      max-height: 650px; /* ËÆæÁΩÆ‰∏Ä‰∏™ÂêàÁêÜÁöÑÊúÄÂ§ßÈ´òÂ∫¶ */
      object-fit: contain;
      aspect-ratio: 4 / 3; /* ËÆæÁΩÆÂõæÁâáÁöÑÂÆΩÈ´òÊØîÔºåËøôÈáå‰ª•4:3‰∏∫‰æã */
    }
  </style>

  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model</title>
  <link rel="icon" type="image/x-icon" href="static\images\icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">üåèHyperSIGMA: <br>Hyperspectral Intelligence Comprehension Foundation Model</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://dotwang.github.io/" target="_blank">Di Wang</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://meiqihu.github.io/" target="_blank">Meiqi Hu</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=PBqyF80AAAAJ" target="_blank">Yao Jin</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=-ec3mwUAAAAJ" target="_blank">Yuchun Miao</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://jqyang22.github.io/" target="_blank">Jiaqi Yang</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=CxKy4lEAAAAJ" target="_blank">Yichu Xu</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.cz/citations?user=gFKE4TMAAAAJ&hl=zh-CN&oi=sra" target="_blank">Xiaolei Qin</a><sup>1,‚ú¢</sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://leonmakise.github.io/" target="_blank">Jiaqi Ma</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/KiwiLYu" target="_blank">Lingyu Sun</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://ieeexplore.ieee.org/author/37089818143" target="_blank">Chenxing Li</a><sup>1,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.researchgate.net/profile/Fu-Chuan" target="_blank">Chuan Fu</a><sup>2,‚ú¢</sup>,
              </span>
              <span class="author-block">
                <a href="https://chrx97.com/" target="_blank">Hongruixuan Chen</a><sup>3,‚ú¢</sup>,
              </span>   
              <br>    
              <span class="author-block">
                <a href="https://chengxihan.github.io/" target="_blank">Chengxi Han</a><sup>1,üìß</sup>,
              </span>
              <span class="author-block">
                <a href="https://naotoyokoya.com/" target="_blank">Naoto Yokoya</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=9jH5v74AAAAJ&hl=en" target="_blank">Jing Zhang</a><sup>1,üìß</sup>,
              </span>       
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Minqiang_Xu1" target="_blank">Minqiang Xu</a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a href="https://ieeexplore.ieee.org/author/37090050631" target="_blank">Lin Liu</a><sup>4</sup>,
              </span>  
              <br>    
              <span class="author-block">
                <a href="https://cs.whu.edu.cn/info/1019/2889.htm" target="_blank">Lefei Zhang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://jszy.whu.edu.cn/wuchen/en/index.htm" target="_blank">Chen Wu</a><sup>1,üìß</sup>,
              </span>
              <span class="author-block">
                <a href="https://cs.whu.edu.cn/info/1019/2892.htm" target="_blank">Bo Du</a><sup>1,üìß</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en" target="_blank">Dacheng Tao</a><sup>5</sup>,
              </span>       
              <span class="author-block">
                <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank">Liangpei Zhang</a><sup>1,üìß</sup>,
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <img src="static\images\whu.png" width="10%"/> 
                    <img src="static\images\cqu.jpg" width="10%"/> 
                    <img src="static\images\utokyo.png" width="30%"/>
                    <img src="static\images\NERC-SLIP.jpg" width="10%"/> 
                    <img src="static\images\NTU.jpg" width="25%"/>
                    <span class="author-block">Wuhan University<sup>1</sup> &nbsp &nbsp &nbsp Chongqing University<sup>2</sup> &nbsp &nbsp &nbsp The University of Tokyo<sup>3</sup><br>National Engineering Research Center of Speech and Language Information Processing<sup>4</sup><br>Nanyang Technological University<sup>5</sup><br><b>Under Peer Review</b></span>
                    <span class="eql-cntrb"><small><br><sup>‚ú¢</sup>: Equal Contribution</small>, <small><sup>üìß</sup>: Corresponding Author</small><br></span>
                  </div>

                  <div class="column has-text-centered">
                    <h4 class="title is-4">TL;NR: The first billion-level foundation model <br> specifically designed for HSI interpretation!</h4>
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/2306.13653" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/House-yuyu/Perceive-IR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2408.15994" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <center><img src="Fig\radarimg.png" alt="MY ALT TEXT" width="600px" height="600px"/></center>
        <div class="content has-text-justified">
          <p>
            HyperSIGMA is the first billion-level foundation model specifically designed for HSI interpretation. To tackle the spectral and spatial redundancy challenges in HSIs, we introduce a novel sparse sampling attention (SSA) mechanism, which effectively promotes the learning of diverse contextual features and serves as the basic block of HyperSIGMA. HyperSIGMA integrates spatial and spectral features using a specially designed spectral enhancement module.
          </p>
        </div>
        <center><img src="Fig\framework.png" alt="MY ALT TEXT" width="800px" /></center>
        <div class="content has-text-justified">
          <p>
            Extensive experiments on various high-level and low-level HSI tasks demonstrate HyperSIGMA‚Äôs versatility and superior representational capability compared to current state-of-the-art methods. It outperforms advanced models like SpectralGPT, even those specifically designed for these tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->





<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Datasets</h2>
        <!-- Your image here -->
        <center><img src="Fig\dataset.png"  alt="MY ALT TEXT" width="800px" /></center>
        <h2 class="subtitle has-text-lefted">
          To train the foundational model, we collected hyperspectral remote sensing image samples from around the globe, constructing a large-scale hyperspectral dataset named HyperGlobal-450K for pre-training. HyperGlobal-450K contains over 20 million three-band images, far exceeding the scale of existing hyperspectral datasets.
        </h2>
    </div>
  </div>
</section>
<!-- End image carousel -->


<section class="hero teaser is-light">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Pretrained Models</h2>
      <table style="border-collapse: collapse; width: 150%; font-size: 1.2em;">
        <thead>
          <tr style="border-bottom: 2px solid black;">
            <th style="padding: 10px; text-align: left;">Pretrain</th>
            <th style="padding: 10px; text-align: left;">Backbone</th>
            <th style="padding: 10px; text-align: left;">Model Weights</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td style="padding: 10px;">Spatial_MAE</td>
            <td style="padding: 10px;">ViT-B</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/1kShixCeWhPGde-vLLxQLJg?pwd=vruc" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spat-vit-base-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
          <tr>
            <td style="padding: 10px;">Spatial_MAE</td>
            <td style="padding: 10px;">ViT-L</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/11iwHFh8sfg9S-inxOYtJlA?pwd=d2qs" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spat-vit-large-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
          <tr>
            <td style="padding: 10px;">Spatial_MAE</td>
            <td style="padding: 10px;">ViT-H</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/1gV9A_XmTCBRw90zjSt90ZQ?pwd=knuu" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spat-vit-huge-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
          <tr>
            <td style="padding: 10px;">Spectral_MAE</td>
            <td style="padding: 10px;">ViT-B</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/1VinBf4qnN98aa6z7TZ-ENQ?pwd=mi2y" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spec-vit-base-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
          <tr>
            <td style="padding: 10px;">Spectral_MAE</td>
            <td style="padding: 10px;">ViT-L</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/1tF2rG-T_65QA3UaG4K9Lhg?pwd=xvdd" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spec-vit-large-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
          <tr>
            <td style="padding: 10px;">Spectral_MAE</td>
            <td style="padding: 10px;">ViT-H</td>
            <td style="padding: 10px;">
              <a href="https://pan.baidu.com/s/1Di9ffWuzxPZUagBCU4Px2w?pwd=bi9r" target="_blank">Baidu Drive</a> &amp; 
              <a href="https://huggingface.co/WHU-Sigma/HyperSIGMA/blob/main/spec-vit-huge-ultra-checkpoint-1599.pth" target="_blank">Hugging Face</a>
            </td>
          </tr>
        </tbody>
      </table>
      
    </div>
  </div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Visual Comparisons</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <h3 class="title is-4">All-in-one Results</h3>
        <!-- Your image here -->
        <img src="fig\multi_degradation.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparisons of Perceive-IR with state-of-the-art all-in-one methods for All-in-One (‚ÄúN+H+R‚Äù) setting. Zoom-in for best view.
        </h2>
      </div>
      <div class="item">
        <h3 class="title is-4">Single-task Results</h3>
        <!-- Your image here -->
        <img src="fig\3_single_task_visual.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparisons of Perceive-IR with state-of-the-art all-in-one methods for One-by-One setting. Zoom-in for best view.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<div class="comparison-slider-wrapper outlined">

  <div class="image-selector">
      <!-- JS-generated -->
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
  </div>

  <div class="comparison-slider noselect">
      <div id="loading-placeholder" class="tall"></div>
      <div id="right-imgs" showing="loading">
        <img id="right" src="Fig\radarimg.png" alt="Right Image" style="width: 10%;">
        <img id="right" src="Fig\radarimg.png" alt="Right Image" style="width: 10%;">
        <img id="right" src="Fig\radarimg.png" alt="Right Image" style="width: 10%;">
      </div>
      <div class="resize noselect" id="left-img">
        <img id="left" src="Fig\logo.png" alt="Left Image" style="width: 10%;">
        <img id="left" src="Fig\logo.png" alt="Left Image" style="width: 10%;">
        <img id="left" src="Fig\logo.png" alt="Left Image" style="width: 10%;">
      </div>
      <div class="left-selector">
          <div class="btn-group-vertical" role="group">
              <button type="button" class="btn btn-dark btn-block disabled-button highlighted" id="left-info-button" disabled>HiFiC (Ours)</button>
          </div>
      </div>
  </div>

  <div class="image-selector">
      <!-- JS-generated -->
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
      <img class="thumb" src="Fig\dataset.png" style="width: 10%;"/>
  </div>

</div>


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Statement</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <h3 class="title is-4">Visual Results of Loss Combinations</h3>
        <!-- Your image here -->
        <img src="fig\loss_visual.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Visual comparison of the restored images obtained using the individual loss schemes and the proposed scheme.
        </h2>
      </div>
      <div class="item">
        <h3 class="title is-4">Performance under Different Loss Ratio</h3>
        <!-- Your image here -->
        <img src="fig\loss_setting.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Comparison of PSNR and SSIM with different weight between different loss function on the Rain100L dataset. red, blue, and green are the weights Œª1, Œª2, and Œª3, respectively.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{hypersigma,
          title={HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model},
          author={Wang, Di and Hu, Meiqi and Jin, Yao and Miao, Yuchun and Yang, Jiaqi and Xu, Yichu and Qin, Xiaolei and Ma, Jiaqi and Sun, Lingyu and Li, Chenxing and Fu, Chuan and Chen, Hongruixuan and Han, Chengxi and Yokoya, Naoto and Zhang, Jing and Xu, Minqiang and Liu, Lin and Zhang, Lefei and Wu, Chen and Du, Bo and Tao, Dacheng and Zhang, Liangpei},
          journal={arXiv preprint arXiv:2406.11519},
          year={2024}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>



  </body>
  </html>